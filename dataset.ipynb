{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create H, A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/raw/tdec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-17 09:41:09 WARNING: Language id package default expects mwt, which has been added\n",
      "2023-08-17 09:41:10 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-08-17 09:41:10 INFO: Using device: cpu\n",
      "2023-08-17 09:41:10 INFO: Loading: tokenize\n",
      "2023-08-17 09:41:10 INFO: Loading: mwt\n",
      "2023-08-17 09:41:10 INFO: Loading: pos\n",
      "2023-08-17 09:41:10 INFO: Loading: lemma\n",
      "2023-08-17 09:41:10 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"id\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = dfs.filter(['headline'], axis=1)\n",
    "H.columns = ['H']\n",
    "\n",
    "A = dfs.filter(['body'], axis=1)\n",
    "A.columns = ['A']\n",
    "A['A'] = dfs['headline'] + '. ' + A['A']\n",
    "\n",
    "S = dfs.filter(['body'], axis=1)\n",
    "S.columns = ['S']\n",
    "S['S'] = dfs['headline'] + '. ' + S['S']\n",
    "in_S = list(S['S'].apply(lambda h: stanza.Document([], text=h)))\n",
    "out_S = nlp(in_S)\n",
    "S = pd.DataFrame([s.text for a in out_S for s in a.sentences], columns=['S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'H': H,\n",
    "    'A': A,\n",
    "    'S': S\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/small/HAS.pickle', 'wb') as f:\n",
    "    pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./datasets/small/HAS.pickle', 'rb') as f:\n",
    "    HAS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-17 10:02:19 WARNING: Language id package default expects mwt, which has been added\n",
      "2023-08-17 10:02:19 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-08-17 10:02:19 INFO: Using device: cpu\n",
      "2023-08-17 10:02:19 INFO: Loading: tokenize\n",
      "2023-08-17 10:02:19 INFO: Loading: mwt\n",
      "2023-08-17 10:02:19 INFO: Loading: pos\n",
      "2023-08-17 10:02:20 INFO: Loading: lemma\n",
      "2023-08-17 10:02:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"id\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "allowed_pos = ['NOUN', 'PROPN', 'VERB', 'X']\n",
    "\n",
    "def preprocess_clw(out_df, c=False, l=False, w=False, n=False):\n",
    "    r = [] # result\n",
    "    if n:\n",
    "        r_t = []\n",
    "    for d in out_df:\n",
    "        tokens = []\n",
    "        for s in d.sentences:\n",
    "            for token in s.words:\n",
    "                _token = token.text\n",
    "                if w:\n",
    "                    if token.upos not in allowed_pos:\n",
    "                        continue\n",
    "                if l:\n",
    "                    _token = token.lemma if token.lemma else _token\n",
    "                if c:\n",
    "                    _token = _token if l else token.text.lower()\n",
    "                tokens.append(_token)\n",
    "        r.append(' '.join(tokens))\n",
    "        if n:\n",
    "            r_t.append(tokens)\n",
    "    if n:\n",
    "        bigram = Phrases(r_t).freeze()\n",
    "        trigram = Phrases(bigram[r_t]).freeze()\n",
    "        r = [' '.join(d) for d in trigram[bigram[r_t]]]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from utils import e_variant\n",
    "\n",
    "def preprocess(HAS):\n",
    "    r = {} # result\n",
    "    r_time = {}\n",
    "    variant = e_variant()\n",
    "    nlp_datasets = {}\n",
    "    for v in variant:\n",
    "        t_start = time()\n",
    "        if v[0] not in nlp_datasets:\n",
    "            in_doc = list(HAS[v[0]][v[0]].apply(lambda x: stanza.Document([], text=x)))\n",
    "            out_doc = nlp(in_doc)\n",
    "            nlp_datasets[v[0]] = out_doc\n",
    "        process_C = 'C' in v\n",
    "        process_L = 'L' in v\n",
    "        process_W = 'W' in v\n",
    "        process_N = 'N' in v\n",
    "        r[v] = preprocess_clw(\n",
    "            nlp_datasets[v[0]],\n",
    "            c=process_C,\n",
    "            l=process_L,\n",
    "            w=process_W,\n",
    "            n=process_N\n",
    "        )\n",
    "        t_end = time()\n",
    "        r_time[v] = t_end - t_start\n",
    "    with open('./datasets/small/HAS_pt.pickle', 'wb') as f:\n",
    "        pickle.dump(r_time, f, pickle.HIGHEST_PROTOCOL)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_p = preprocess(HAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/small/HAS_p.pickle', 'wb') as f:\n",
    "    pickle.dump(HAS_p, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
