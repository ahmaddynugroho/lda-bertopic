{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create H, A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/raw/tdec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.sample(100, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-19 11:43:27 WARNING: Language id package default expects mwt, which has been added\n",
      "2023-08-19 11:43:28 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-08-19 11:43:28 INFO: Using device: cpu\n",
      "2023-08-19 11:43:28 INFO: Loading: tokenize\n",
      "2023-08-19 11:43:28 INFO: Loading: mwt\n",
      "2023-08-19 11:43:28 INFO: Loading: pos\n",
      "2023-08-19 11:43:28 INFO: Loading: lemma\n",
      "2023-08-19 11:43:28 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"id\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "_HAS_t = {}\n",
    "\n",
    "t_start = time()\n",
    "H = dfs.filter(['headline'], axis=1)\n",
    "H.columns = ['H']\n",
    "\n",
    "_HAS_t['H'] = time() - t_start\n",
    "A = dfs.filter(['body'], axis=1)\n",
    "A.columns = ['A']\n",
    "A['A'] = dfs['headline'] + '. ' + A['A']\n",
    "\n",
    "# _HAS_t['A'] = time() - _HAS_t['H']\n",
    "# S = dfs.filter(['body'], axis=1)\n",
    "# S.columns = ['S']\n",
    "# S['S'] = dfs['headline'] + '. ' + S['S']\n",
    "# in_S = list(S['S'].apply(lambda h: stanza.Document([], text=h)))\n",
    "# out_S = nlp(in_S)\n",
    "# S = pd.DataFrame([s.text for a in out_S for s in a.sentences], columns=['S'])\n",
    "\n",
    "# _HAS_t['S'] = time() - _HAS_t['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from utils import e_variant\n",
    "\n",
    "HAS_t = pd.DataFrame(pd.Series(e_variant()), columns=['variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for v in HAS_t['variant']:\n",
    "    r.append(_HAS_t[v[0]])\n",
    "HAS_t['segmentation'] = pd.Series(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWN</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  segmentation\n",
       "0     HWN      0.001003"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAS = pd.concat([H, A, S], axis=1)\n",
    "HAS = pd.concat([H, A], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_t.to_parquet('./results/HAS_t.parquet')\n",
    "HAS.to_parquet('./results/HAS.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HAS = pd.read_parquet('./results/HAS.parquet')\n",
    "HAS_t = pd.read_parquet('./results/HAS_t.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 11:43:38 WARNING: Language id package default expects mwt, which has been added\n",
      "2023-08-19 11:43:39 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-08-19 11:43:39 INFO: Using device: cpu\n",
      "2023-08-19 11:43:39 INFO: Loading: tokenize\n",
      "2023-08-19 11:43:39 INFO: Loading: mwt\n",
      "2023-08-19 11:43:39 INFO: Loading: pos\n",
      "2023-08-19 11:43:39 INFO: Loading: lemma\n",
      "2023-08-19 11:43:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"id\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "allowed_pos = ['NOUN', 'PROPN', 'VERB', 'X']\n",
    "\n",
    "def preprocess_clw(out_df, c=False, l=False, w=False, n=False):\n",
    "    r = [] # result\n",
    "    if n:\n",
    "        r_t = []\n",
    "    for d in out_df:\n",
    "        tokens = []\n",
    "        for s in d.sentences:\n",
    "            for token in s.words:\n",
    "                _token = token.text\n",
    "                if w:\n",
    "                    if token.upos not in allowed_pos:\n",
    "                        continue\n",
    "                if l:\n",
    "                    _token = token.lemma if token.lemma else _token\n",
    "                if c:\n",
    "                    _token = _token if l else token.text.lower()\n",
    "                tokens.append(_token)\n",
    "        r.append(' '.join(tokens))\n",
    "        if n:\n",
    "            r_t.append(tokens)\n",
    "    if n:\n",
    "        bigram = Phrases(r_t).freeze()\n",
    "        trigram = Phrases(bigram[r_t]).freeze()\n",
    "        r = [' '.join(d) for d in trigram[bigram[r_t]]]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from utils import e_variant\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "    t_start = time()\n",
    "    nlp_datasets = {}\n",
    "    for v in e_variant():\n",
    "        df = HAS[v[0]].dropna()\n",
    "        in_doc = list(df.apply(lambda x: stanza.Document([], text=x)))\n",
    "        out_doc = nlp(in_doc)\n",
    "        nlp_datasets[v[0]] = out_doc\n",
    "    t_base = time() - t_start\n",
    "    r = {} # result\n",
    "    r_time = []\n",
    "    variant = e_variant()\n",
    "    for v in variant:\n",
    "        t_preprocess = time()\n",
    "        process_C = 'C' in v\n",
    "        process_L = 'L' in v\n",
    "        process_W = 'W' in v\n",
    "        process_N = 'N' in v\n",
    "        r[v] = pd.Series(preprocess_clw(\n",
    "            nlp_datasets[v[0]],\n",
    "            c=process_C,\n",
    "            l=process_L,\n",
    "            w=process_W,\n",
    "            n=process_N\n",
    "        ))\n",
    "        r_time.append(time() - t_preprocess + t_base)\n",
    "    HAS_t['preprocess'] = pd.Series(r_time)\n",
    "    return pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_p = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWN</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>2.34099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  segmentation  preprocess\n",
       "0     HWN      0.001003     2.34099"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_p\n",
    "HAS_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_p.to_parquet('./results/HAS_p.parquet')\n",
    "HAS_t.to_parquet('./results/HAS_t.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
