{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FILE_PREPROCESSED = './results/ds.parquet'\n",
    "PATH_FILE_ELAPSE_TIME = './results/elapse_time.csv'\n",
    "PATH_FILE_EVALUATION_LDA = './results/evaluation_lda.csv'\n",
    "PATH_FILE_EVALUATION_BERTOPIC = './results/evaluation_bertopic.csv'\n",
    "PATH_PREFIX_MODEL_LDA = './results/models_lda/'\n",
    "PATH_PREFIX_MODEL_BERTOPIC = './results/models_bertopic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.read_parquet(PATH_FILE_PREPROCESSED)\n",
    "elapse_time = pd.read_csv(PATH_FILE_ELAPSE_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/civbag/repo/lda-bertopic/.venv/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/civbag/repo/lda-bertopic/.venv/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/civbag/repo/lda-bertopic/.venv/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/civbag/repo/lda-bertopic/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/civbag/repo/lda-bertopic/.venv/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from utils import get_coherence, get_diversity, get_topics_lda, get_topics_bertopic\n",
    "\n",
    "\n",
    "def load_eval(variant, bertopic=False):\n",
    "    t_start = time()\n",
    "    docs = ds[variant].dropna()\n",
    "    if bertopic:\n",
    "        model = BERTopic.load(f'{PATH_PREFIX_MODEL_BERTOPIC}{variant}')\n",
    "        topics = get_topics_bertopic(model)\n",
    "        analyzer = model.vectorizer_model.build_analyzer()\n",
    "        texts = [' '.join(doc) for doc in docs] if 'B' not in v else docs\n",
    "        texts = [analyzer(doc) for doc in texts]\n",
    "        dictionary = Dictionary(texts)\n",
    "    else:\n",
    "        model = LdaMulticore.load(f'{PATH_PREFIX_MODEL_LDA}{variant}')\n",
    "        topics = get_topics_lda(model, model.id2word)\n",
    "        texts = docs\n",
    "        dictionary = model.id2word\n",
    "    c = get_coherence(\n",
    "        topics=topics,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary\n",
    "    )\n",
    "    d = get_diversity(topics)\n",
    "    total_time = time() - t_start\n",
    "    return ({\n",
    "        'variant': variant,\n",
    "        'coherence': c,\n",
    "        'diversity': d,\n",
    "        'score': c*d\n",
    "    }, total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LDA DCLW: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "lda_eval = []\n",
    "elapse_time_lda = []\n",
    "\n",
    "for v in (tds := tqdm(ds.columns)):\n",
    "    tds.set_description(f'Evaluating LDA {v}')\n",
    "    if 'B' in v: \n",
    "        elapse_time_lda.append(0)\n",
    "        continue\n",
    "    lda_score, lda_time = load_eval(v)\n",
    "    lda_eval.append(lda_score)\n",
    "    elapse_time_lda.append(lda_time)\n",
    "\n",
    "lda_eval = pd.DataFrame(lda_eval)\n",
    "elapse_time['lda_evaluation'] = pd.Series(elapse_time_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BERTopic DCLW: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "bertopic_eval = []\n",
    "elapse_time_bertopic = []\n",
    "\n",
    "for v in (tds := tqdm(ds.columns)):\n",
    "    tds.set_description(f'Evaluating BERTopic {v}')\n",
    "    if 'T' in v: \n",
    "        elapse_time_bertopic.append(0)\n",
    "        continue\n",
    "    bertopic_score, bertopic_time = load_eval(v, bertopic=True)\n",
    "    bertopic_eval.append(bertopic_score)\n",
    "    elapse_time_bertopic.append(bertopic_time)\n",
    "\n",
    "bertopic_eval = pd.DataFrame(bertopic_eval)\n",
    "elapse_time['bertopic_evaluation'] = pd.Series(elapse_time_bertopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>coherence</th>\n",
       "      <th>diversity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dCSW</td>\n",
       "      <td>0.366997</td>\n",
       "      <td>0.043056</td>\n",
       "      <td>0.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCSW</td>\n",
       "      <td>0.417495</td>\n",
       "      <td>0.437895</td>\n",
       "      <td>0.182819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dCLW</td>\n",
       "      <td>0.342679</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.105741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCLW</td>\n",
       "      <td>0.405463</td>\n",
       "      <td>0.167391</td>\n",
       "      <td>0.067871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  coherence  diversity     score\n",
       "0    dCSW   0.366997   0.043056  0.015801\n",
       "1    DCSW   0.417495   0.437895  0.182819\n",
       "2    dCLW   0.342679   0.308571  0.105741\n",
       "3    DCLW   0.405463   0.167391  0.067871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>coherence</th>\n",
       "      <th>diversity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dCSW</td>\n",
       "      <td>0.646014</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.600092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCSW</td>\n",
       "      <td>0.598728</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.568792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dCLW</td>\n",
       "      <td>0.640805</td>\n",
       "      <td>0.914118</td>\n",
       "      <td>0.585771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCLW</td>\n",
       "      <td>0.584094</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.554889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  coherence  diversity     score\n",
       "0    dCSW   0.646014   0.928916  0.600092\n",
       "1    DCSW   0.598728   0.950000  0.568792\n",
       "2    dCLW   0.640805   0.914118  0.585771\n",
       "3    DCLW   0.584094   0.950000  0.554889"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertopic_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>nlp</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>lda_training</th>\n",
       "      <th>bertopic_training</th>\n",
       "      <th>lda_evaluation</th>\n",
       "      <th>bertopic_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dCSW</td>\n",
       "      <td>40.981253</td>\n",
       "      <td>1.658864</td>\n",
       "      <td>3.349057</td>\n",
       "      <td>6.923768</td>\n",
       "      <td>0.699681</td>\n",
       "      <td>1.822078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCSW</td>\n",
       "      <td>40.981253</td>\n",
       "      <td>1.658865</td>\n",
       "      <td>7.551509</td>\n",
       "      <td>2.469865</td>\n",
       "      <td>2.293074</td>\n",
       "      <td>0.270443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dCLW</td>\n",
       "      <td>40.981253</td>\n",
       "      <td>0.075823</td>\n",
       "      <td>6.950676</td>\n",
       "      <td>6.947025</td>\n",
       "      <td>1.037146</td>\n",
       "      <td>1.932556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCLW</td>\n",
       "      <td>40.981253</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>3.171497</td>\n",
       "      <td>2.534088</td>\n",
       "      <td>0.839975</td>\n",
       "      <td>0.272668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant        nlp  preprocessing  lda_training  bertopic_training  \\\n",
       "0    dCSW  40.981253       1.658864      3.349057           6.923768   \n",
       "1    DCSW  40.981253       1.658865      7.551509           2.469865   \n",
       "2    dCLW  40.981253       0.075823      6.950676           6.947025   \n",
       "3    DCLW  40.981253       0.075824      3.171497           2.534088   \n",
       "\n",
       "   lda_evaluation  bertopic_evaluation  \n",
       "0        0.699681             1.822078  \n",
       "1        2.293074             0.270443  \n",
       "2        1.037146             1.932556  \n",
       "3        0.839975             0.272668  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapse_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapse_time.to_csv(PATH_FILE_ELAPSE_TIME, index=False)\n",
    "lda_eval.to_csv(PATH_FILE_EVALUATION_LDA, index=False)\n",
    "bertopic_eval.to_csv(PATH_FILE_EVALUATION_BERTOPIC, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
