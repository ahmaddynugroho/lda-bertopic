{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "H = pd.read_csv('./datasets/small/HCLW.csv')\n",
    "A = pd.read_csv('./datasets/small/ACLW.csv')\n",
    "S = pd.read_csv('./datasets/small/SCLW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def create_embedding(name, df_column):\n",
    "    r = {} # result\n",
    "    df_column = df_column.dropna()\n",
    "    r['name'] = name\n",
    "    t_lda = time()\n",
    "    r['T'] = [d.split(' ') for d in df_column]\n",
    "    r['id2word'] = Dictionary(r['T'])\n",
    "    r['corpus'] = [r['id2word'].doc2bow(d) for d in r['T']]\n",
    "    t_bertopic = time()\n",
    "    r['embeddings'] = sentence_model.encode(list(df_column))\n",
    "    t_end = time()\n",
    "    r['time'] = {\n",
    "        'lda_embeddings': t_bertopic - t_lda,\n",
    "        'bertopic_embeddings': t_end - t_bertopic\n",
    "    }\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_H = {\n",
    "    'HT': create_embedding('HT', H['T']),\n",
    "    'HC': create_embedding('HC', H['C']),\n",
    "    'HCL': create_embedding('HCL', H['CL']),\n",
    "    'HCLW': create_embedding('HCLW', H['CLW']),\n",
    "    'HCW': create_embedding('HCW', H['CW']),\n",
    "    'HL': create_embedding('HL', H['L']),\n",
    "    'HLW': create_embedding('HLW', H['LW']),\n",
    "    'HW': create_embedding('HW', H['W']),\n",
    "}\n",
    "e_A = {\n",
    "    'AT': create_embedding('AT', A['T']),\n",
    "    'AC': create_embedding('AC', A['C']),\n",
    "    'ACL': create_embedding('ACL', A['CL']),\n",
    "    'ACLW': create_embedding('ACLW', A['CLW']),\n",
    "    'ACW': create_embedding('ACW', A['CW']),\n",
    "    'AL': create_embedding('AL', A['L']),\n",
    "    'ALW': create_embedding('ALW', A['LW']),\n",
    "    'AW': create_embedding('AW', A['W']),\n",
    "}\n",
    "e_S = {\n",
    "    'ST': create_embedding('ST', S['T']),\n",
    "    'SC': create_embedding('SC', S['C']),\n",
    "    'SCL': create_embedding('SCL', S['CL']),\n",
    "    'SCLW': create_embedding('SCLW', S['CLW']),\n",
    "    'SCW': create_embedding('SCW', S['CW']),\n",
    "    'SL': create_embedding('SL', S['L']),\n",
    "    'SLW': create_embedding('SLW', S['LW']),\n",
    "    'SW': create_embedding('SW', S['W']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('./datasets/small/embeddings/e_H.pickle', 'wb') as f:\n",
    "#     pickle.dump(e_H, f, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "# with open('./datasets/small/embeddings/e_A.pickle', 'wb') as f:\n",
    "#     pickle.dump(e_A, f, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "# with open('./datasets/small/embeddings/e_S.pickle', 'wb') as f:\n",
    "#     pickle.dump(e_S, f, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
