{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.read_parquet('./results/ds.parquet')\n",
    "elapse_time = pd.read_csv('./results/elapse_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from utils import get_diversity, get_topics_lda\n",
    "import optuna\n",
    "\n",
    "def lda(docs):\n",
    "    docs = docs.dropna()\n",
    "    dictionary = Dictionary(docs)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    def objective(trial, get_lda=False):\n",
    "        num_topics = trial.suggest_int('num_topics', 5, 100)\n",
    "        alpha = trial.suggest_categorical('alpha_categorical', ['symmetric', 'asymmetric', 'scalar'])\n",
    "        eta = trial.suggest_categorical('eta_categorical', ['symmetric', 'auto', 'scalar'])\n",
    "        if alpha == 'scalar':\n",
    "            alpha = trial.suggest_float('alpha', 0.01, 1)\n",
    "        if eta == 'scalar':\n",
    "            eta = trial.suggest_float('eta', 0.01, 1)\n",
    "        model = LdaMulticore(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            alpha=alpha,\n",
    "            eta=eta,\n",
    "        )\n",
    "        if get_lda:\n",
    "            return model\n",
    "        c = CoherenceModel(model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "        cs = c.get_coherence()\n",
    "        ts = get_diversity(get_topics_lda(model, dictionary))\n",
    "        return cs * ts\n",
    "\n",
    "    t_start = time()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2) # FIXME: change n to 20\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_lda = objective(best_trial, get_lda=True)\n",
    "    t_end = time()\n",
    "\n",
    "    return {\n",
    "        'model': best_lda,\n",
    "        'time': t_end - t_start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_lda():\n",
    "    r_time = []\n",
    "    for v in ds:\n",
    "        model = lda(ds[v])\n",
    "        model['model'].save(f'./results/models_lda/{v}')\n",
    "        r_time.append(model['time'])\n",
    "    elapse_time['lda_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 12:30:53,448] A new study created in memory with name: no-name-0f4fb4fe-fca7-45f0-a603-ce48df168b50\n",
      "[I 2023-08-22 12:31:01,821] Trial 0 finished with value: 0.06670738096745027 and parameters: {'num_topics': 9, 'alpha_categorical': 'scalar', 'eta_categorical': 'symmetric', 'alpha': 0.9457040041108908}. Best is trial 0 with value: 0.06670738096745027.\n",
      "[I 2023-08-22 12:31:10,563] Trial 1 finished with value: 0.09778219631563202 and parameters: {'num_topics': 6, 'alpha_categorical': 'scalar', 'eta_categorical': 'symmetric', 'alpha': 0.5020961367739877}. Best is trial 1 with value: 0.09778219631563202.\n",
      "[I 2023-08-22 12:31:15,795] A new study created in memory with name: no-name-8f5f1d19-165c-4775-8049-0dde7ee19101\n",
      "[I 2023-08-22 12:31:23,474] Trial 0 finished with value: 0.035998249244859906 and parameters: {'num_topics': 10, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'scalar', 'eta': 0.7075572669291939}. Best is trial 0 with value: 0.035998249244859906.\n",
      "[I 2023-08-22 12:31:33,744] Trial 1 finished with value: 0.04534287878247924 and parameters: {'num_topics': 64, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 1 with value: 0.04534287878247924.\n",
      "[I 2023-08-22 12:31:37,772] A new study created in memory with name: no-name-2b198410-ce41-4f60-a89e-c4257233700a\n",
      "[I 2023-08-22 12:31:49,775] Trial 0 finished with value: 0.26753202398213866 and parameters: {'num_topics': 76, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.26753202398213866.\n",
      "[I 2023-08-22 12:32:00,176] Trial 1 finished with value: 0.2917614093981863 and parameters: {'num_topics': 55, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 1 with value: 0.2917614093981863.\n",
      "[I 2023-08-22 12:32:04,425] A new study created in memory with name: no-name-a7e330ac-ccac-4796-aac6-689225666a6f\n",
      "[I 2023-08-22 12:32:12,227] Trial 0 finished with value: 0.13098619147893065 and parameters: {'num_topics': 17, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.13098619147893065.\n",
      "[I 2023-08-22 12:32:19,675] Trial 1 finished with value: 0.11810034002203121 and parameters: {'num_topics': 10, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.13098619147893065.\n"
     ]
    }
   ],
   "source": [
    "save_models_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>nlp</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>lda_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dCL</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>22.314663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCL</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>21.944010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dLWN</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.097994</td>\n",
       "      <td>26.633091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DLWN</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.184994</td>\n",
       "      <td>18.792636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant       nlp  preprocessing  lda_training\n",
       "0     dCL  26.75152       0.015996     22.314663\n",
       "1     DCL  26.75152       0.015996     21.944010\n",
       "2    dLWN  26.75152       0.097994     26.633091\n",
       "3    DLWN  26.75152       0.184994     18.792636"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "embedding_model = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "def save_models_bertopic():\n",
    "    path_prefix = './results/models_bertopic/'\n",
    "    r_time = []\n",
    "    for v in ds:\n",
    "        t_start = time()\n",
    "        docs = ds[v].dropna()\n",
    "        docs = [' '.join(doc) for doc in docs]\n",
    "        bertopic = BERTopic(language='multilingual', embedding_model=embedding_model)\n",
    "        model = bertopic.fit(docs)\n",
    "        t_end = time()\n",
    "        model.save(\n",
    "            f\"{path_prefix}{v}\",\n",
    "            serialization=\"safetensors\",\n",
    "            save_embedding_model=embedding_model,\n",
    "            save_ctfidf=True,\n",
    "        )\n",
    "        r_time.append(t_end - t_start)\n",
    "    elapse_time['bertopic_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_bertopic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>nlp</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>lda_training</th>\n",
       "      <th>bertopic_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dCL</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>22.314663</td>\n",
       "      <td>57.348722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCL</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>21.944010</td>\n",
       "      <td>11.408381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dLWN</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.097994</td>\n",
       "      <td>26.633091</td>\n",
       "      <td>35.589177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DLWN</td>\n",
       "      <td>26.75152</td>\n",
       "      <td>0.184994</td>\n",
       "      <td>18.792636</td>\n",
       "      <td>12.978124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant       nlp  preprocessing  lda_training  bertopic_training\n",
       "0     dCL  26.75152       0.015996     22.314663          57.348722\n",
       "1     DCL  26.75152       0.015996     21.944010          11.408381\n",
       "2    dLWN  26.75152       0.097994     26.633091          35.589177\n",
       "3    DLWN  26.75152       0.184994     18.792636          12.978124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapse_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapse_time.to_csv('./results/elapse_time.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
