{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HAS_p = pd.read_parquet('./results/HAS_p.parquet')\n",
    "HAS_t = pd.read_parquet('./results/HAS_t.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from utils import get_diversity, get_topics_lda\n",
    "import optuna\n",
    "\n",
    "def lda(docs):\n",
    "    docs = docs.dropna()\n",
    "    dictionary = Dictionary(docs)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    def objective(trial, get_lda=False):\n",
    "        num_topics = trial.suggest_int('num_topics', 5, 100)\n",
    "        alpha = trial.suggest_categorical('alpha_categorical', ['symmetric', 'asymmetric', 'scalar'])\n",
    "        eta = trial.suggest_categorical('eta_categorical', ['symmetric', 'auto', 'scalar'])\n",
    "        if alpha == 'scalar':\n",
    "            alpha = trial.suggest_float('alpha', 0.01, 1)\n",
    "        if eta == 'scalar':\n",
    "            eta = trial.suggest_float('eta', 0.01, 1)\n",
    "        model = LdaMulticore(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            alpha=alpha,\n",
    "            eta=eta,\n",
    "        )\n",
    "        if get_lda:\n",
    "            return model\n",
    "        c = CoherenceModel(model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "        cs = c.get_coherence()\n",
    "        ts = get_diversity(get_topics_lda(model, dictionary))\n",
    "        return cs * ts\n",
    "\n",
    "    t_start = time()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2) # FIXME: change n to 20\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_lda = objective(best_trial, get_lda=True)\n",
    "    t_end = time()\n",
    "\n",
    "    return {\n",
    "        'model': best_lda,\n",
    "        'time': t_end - t_start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_lda():\n",
    "    r_time = []\n",
    "    for v in HAS_p:\n",
    "        model = lda(HAS_p[v])\n",
    "        model['model'].save(f'./results/models_lda/{v}')\n",
    "        r_time.append(model['time'])\n",
    "    HAS_t['lda_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 13:32:34,777] A new study created in memory with name: no-name-fb1bf378-76ef-4ba3-b674-8db734e3555f\n",
      "[I 2023-08-20 13:32:38,710] Trial 0 finished with value: 0.15279141567222349 and parameters: {'num_topics': 22, 'alpha_categorical': 'scalar', 'eta_categorical': 'auto', 'alpha': 0.5865363891536639}. Best is trial 0 with value: 0.15279141567222349.\n",
      "[I 2023-08-20 13:32:45,636] Trial 1 finished with value: 0.1546685437928849 and parameters: {'num_topics': 60, 'alpha_categorical': 'scalar', 'eta_categorical': 'auto', 'alpha': 0.045783193663668835}. Best is trial 1 with value: 0.1546685437928849.\n",
      "[I 2023-08-20 13:32:49,107] A new study created in memory with name: no-name-1073e3b5-8575-4730-b113-7f445a38d37d\n",
      "[I 2023-08-20 13:32:56,225] Trial 0 finished with value: 0.25213479808158307 and parameters: {'num_topics': 67, 'alpha_categorical': 'scalar', 'eta_categorical': 'scalar', 'alpha': 0.09195557123324236, 'eta': 0.6137199862398901}. Best is trial 0 with value: 0.25213479808158307.\n",
      "[I 2023-08-20 13:33:00,164] Trial 1 finished with value: 0.3858076832991216 and parameters: {'num_topics': 15, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 1 with value: 0.3858076832991216.\n",
      "[I 2023-08-20 13:33:01,858] A new study created in memory with name: no-name-ef325bbd-1e29-4f8b-9757-b1a132eaddff\n",
      "[I 2023-08-20 13:33:13,077] Trial 0 finished with value: 0.2086603699591733 and parameters: {'num_topics': 61, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.2086603699591733.\n",
      "[I 2023-08-20 13:33:25,153] Trial 1 finished with value: 0.1773576631466549 and parameters: {'num_topics': 60, 'alpha_categorical': 'symmetric', 'eta_categorical': 'scalar', 'eta': 0.2426567438011352}. Best is trial 0 with value: 0.2086603699591733.\n",
      "[I 2023-08-20 13:33:29,194] A new study created in memory with name: no-name-e13703b5-6e96-4478-832b-ff84c58f10ad\n",
      "[I 2023-08-20 13:33:40,197] Trial 0 finished with value: 0.19671091054291498 and parameters: {'num_topics': 59, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.19671091054291498.\n",
      "[I 2023-08-20 13:33:48,251] Trial 1 finished with value: 0.022195156488392997 and parameters: {'num_topics': 36, 'alpha_categorical': 'scalar', 'eta_categorical': 'auto', 'alpha': 0.8411024982863948}. Best is trial 0 with value: 0.19671091054291498.\n",
      "[I 2023-08-20 13:33:51,985] A new study created in memory with name: no-name-9fd3d3cd-3b0e-4650-8bd1-b5cc2190f90c\n",
      "[I 2023-08-20 13:34:04,246] Trial 0 finished with value: 0.33110808428098015 and parameters: {'num_topics': 76, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.33110808428098015.\n",
      "[I 2023-08-20 13:34:12,664] Trial 1 finished with value: 0.3152887240594593 and parameters: {'num_topics': 15, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.33110808428098015.\n",
      "[I 2023-08-20 13:34:17,138] A new study created in memory with name: no-name-906c4bae-fbe4-4169-9e3f-df6133e5077a\n",
      "[I 2023-08-20 13:34:30,562] Trial 0 finished with value: 0.25709001150332367 and parameters: {'num_topics': 95, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.25709001150332367.\n",
      "[I 2023-08-20 13:34:39,339] Trial 1 finished with value: 0.004923585593998577 and parameters: {'num_topics': 79, 'alpha_categorical': 'scalar', 'eta_categorical': 'scalar', 'alpha': 0.7689985467659334, 'eta': 0.8588756561931156}. Best is trial 0 with value: 0.25709001150332367.\n"
     ]
    }
   ],
   "source": [
    "save_models_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>lda_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.334094</td>\n",
       "      <td>14.322130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCLWN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.333092</td>\n",
       "      <td>12.726939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWN</td>\n",
       "      <td>1.692513e+09</td>\n",
       "      <td>33.333024</td>\n",
       "      <td>27.309271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACLWN</td>\n",
       "      <td>1.692513e+09</td>\n",
       "      <td>33.355028</td>\n",
       "      <td>22.753088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWN</td>\n",
       "      <td>2.637917e+01</td>\n",
       "      <td>31.438030</td>\n",
       "      <td>25.117920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCLWN</td>\n",
       "      <td>2.637917e+01</td>\n",
       "      <td>31.439039</td>\n",
       "      <td>26.927279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  segmentation  preprocess  lda_training\n",
       "0     HWN  0.000000e+00    1.334094     14.322130\n",
       "1   HCLWN  0.000000e+00    1.333092     12.726939\n",
       "2     AWN  1.692513e+09   33.333024     27.309271\n",
       "3   ACLWN  1.692513e+09   33.355028     22.753088\n",
       "4     SWN  2.637917e+01   31.438030     25.117920\n",
       "5   SCLWN  2.637917e+01   31.439039     26.927279"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "embedding_model = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "def save_models_bertopic():\n",
    "    path_prefix = './results/models_bertopic/'\n",
    "    r_time = []\n",
    "    for v in HAS_p:\n",
    "        t_start = time()\n",
    "        docs = HAS_p[v].dropna()\n",
    "        docs = [' '.join(doc) for doc in docs]\n",
    "        bertopic = BERTopic(language='multilingual', embedding_model=embedding_model)\n",
    "        model = bertopic.fit(docs)\n",
    "        t_end = time()\n",
    "        model.save(\n",
    "            f\"{path_prefix}{v}\",\n",
    "            serialization=\"safetensors\",\n",
    "            save_embedding_model=embedding_model,\n",
    "            save_ctfidf=True,\n",
    "        )\n",
    "        r_time.append(t_end - t_start)\n",
    "    HAS_t['bertopic_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_bertopic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>lda_training</th>\n",
       "      <th>bertopic_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.334094</td>\n",
       "      <td>14.322130</td>\n",
       "      <td>15.278703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCLWN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.333092</td>\n",
       "      <td>12.726939</td>\n",
       "      <td>5.869205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWN</td>\n",
       "      <td>1.692513e+09</td>\n",
       "      <td>33.333024</td>\n",
       "      <td>27.309271</td>\n",
       "      <td>9.887508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACLWN</td>\n",
       "      <td>1.692513e+09</td>\n",
       "      <td>33.355028</td>\n",
       "      <td>22.753088</td>\n",
       "      <td>10.352225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWN</td>\n",
       "      <td>2.637917e+01</td>\n",
       "      <td>31.438030</td>\n",
       "      <td>25.117920</td>\n",
       "      <td>36.455737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCLWN</td>\n",
       "      <td>2.637917e+01</td>\n",
       "      <td>31.439039</td>\n",
       "      <td>26.927279</td>\n",
       "      <td>32.640802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant  segmentation  preprocess  lda_training  bertopic_training\n",
       "0     HWN  0.000000e+00    1.334094     14.322130          15.278703\n",
       "1   HCLWN  0.000000e+00    1.333092     12.726939           5.869205\n",
       "2     AWN  1.692513e+09   33.333024     27.309271           9.887508\n",
       "3   ACLWN  1.692513e+09   33.355028     22.753088          10.352225\n",
       "4     SWN  2.637917e+01   31.438030     25.117920          36.455737\n",
       "5   SCLWN  2.637917e+01   31.439039     26.927279          32.640802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_t.to_parquet('./results/HAS_t.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
