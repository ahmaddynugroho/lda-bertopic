{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('./results/HAS_e.pickle', 'rb') as f:\n",
    "    HAS_e = pickle.load(f)\n",
    "HAS_t = pd.read_parquet('./results/HAS_t.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\repo\\lda-bertopic\\.venv\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from utils import get_diversity, get_topics_lda\n",
    "import optuna\n",
    "\n",
    "def lda(embedding):\n",
    "    def objective(trial, get_lda=False):\n",
    "        num_topics = trial.suggest_int('num_topics', 5, 100)\n",
    "        alpha = trial.suggest_categorical('alpha_categorical', ['symmetric', 'asymmetric', 'scalar'])\n",
    "        eta = trial.suggest_categorical('eta_categorical', ['symmetric', 'auto', 'scalar'])\n",
    "        if alpha == 'scalar':\n",
    "            alpha = trial.suggest_float('alpha', 0.01, 1)\n",
    "        if eta == 'scalar':\n",
    "            eta = trial.suggest_float('eta', 0.01, 1)\n",
    "        model = LdaMulticore(\n",
    "            corpus=embedding['corpus'],\n",
    "            id2word=embedding['id2word'],\n",
    "            num_topics=num_topics,\n",
    "            alpha=alpha,\n",
    "            eta=eta,\n",
    "        )\n",
    "        if get_lda:\n",
    "            return model\n",
    "        c = CoherenceModel(model, texts=embedding['T'], dictionary=embedding['id2word'], coherence='c_v')\n",
    "        cs = c.get_coherence()\n",
    "        ts = get_diversity(get_topics_lda(model, embedding['id2word']))\n",
    "        return cs * ts\n",
    "\n",
    "    t_start = time()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2) # FIXME: change n to 20\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_lda = objective(best_trial, get_lda=True)\n",
    "    t_end = time()\n",
    "\n",
    "    return {\n",
    "        'model': best_lda,\n",
    "        'time': t_end - t_start,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_lda():\n",
    "    r_time = []\n",
    "    for v in HAS_e:\n",
    "        model = lda(HAS_e[v])\n",
    "        model['model'].save(f'./results/models_lda/{v}')\n",
    "        r_time.append(model['time'])\n",
    "    HAS_t['lda_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-19 12:57:28,396] A new study created in memory with name: no-name-4e023c5d-1008-445f-a28f-e65df3e59df2\n",
      "[I 2023-08-19 12:57:37,000] Trial 0 finished with value: 0.25667358882915076 and parameters: {'num_topics': 22, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.25667358882915076.\n",
      "[I 2023-08-19 12:57:47,196] Trial 1 finished with value: 0.18602927535236405 and parameters: {'num_topics': 74, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'scalar', 'eta': 0.040344165527485557}. Best is trial 0 with value: 0.25667358882915076.\n",
      "[I 2023-08-19 12:57:52,047] A new study created in memory with name: no-name-8922a887-c1dc-4238-8dbd-8b8a407a2039\n",
      "[I 2023-08-19 12:58:00,794] Trial 0 finished with value: 0.009972078218902133 and parameters: {'num_topics': 85, 'alpha_categorical': 'scalar', 'eta_categorical': 'symmetric', 'alpha': 0.8496347936839019}. Best is trial 0 with value: 0.009972078218902133.\n",
      "[I 2023-08-19 12:58:09,260] Trial 1 finished with value: 0.25213934114881237 and parameters: {'num_topics': 26, 'alpha_categorical': 'symmetric', 'eta_categorical': 'scalar', 'eta': 0.6943844651058048}. Best is trial 1 with value: 0.25213934114881237.\n",
      "[I 2023-08-19 12:58:14,432] A new study created in memory with name: no-name-b69b419f-49e9-4326-b44e-486fcbae38a1\n",
      "[I 2023-08-19 12:58:24,840] Trial 0 finished with value: 0.13129249100630946 and parameters: {'num_topics': 87, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.13129249100630946.\n",
      "[I 2023-08-19 12:58:35,415] Trial 1 finished with value: 0.1285556059359017 and parameters: {'num_topics': 98, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.13129249100630946.\n",
      "[I 2023-08-19 12:58:40,259] A new study created in memory with name: no-name-a1dfe95d-aba1-4744-a15f-b23483e57f28\n",
      "[I 2023-08-19 12:58:49,081] Trial 0 finished with value: 0.10824917041858477 and parameters: {'num_topics': 82, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'scalar', 'eta': 0.42563778473195946}. Best is trial 0 with value: 0.10824917041858477.\n",
      "[I 2023-08-19 12:58:57,710] Trial 1 finished with value: 0.012627770920672292 and parameters: {'num_topics': 88, 'alpha_categorical': 'scalar', 'eta_categorical': 'scalar', 'alpha': 0.8604139275945818, 'eta': 0.8919484832282304}. Best is trial 0 with value: 0.10824917041858477.\n",
      "[I 2023-08-19 12:59:02,483] A new study created in memory with name: no-name-d1f31b34-335e-456e-a866-d39498858ab9\n",
      "[I 2023-08-19 12:59:19,043] Trial 0 finished with value: 0.04004575991186932 and parameters: {'num_topics': 96, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.04004575991186932.\n",
      "[I 2023-08-19 12:59:29,583] Trial 1 finished with value: 0.032351945720328734 and parameters: {'num_topics': 12, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.04004575991186932.\n",
      "[I 2023-08-19 12:59:36,065] A new study created in memory with name: no-name-f5f51aa8-e14f-494f-916e-d3a18fb14b35\n",
      "[I 2023-08-19 12:59:49,810] Trial 0 finished with value: 0.028393254995785946 and parameters: {'num_topics': 54, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'symmetric'}. Best is trial 0 with value: 0.028393254995785946.\n",
      "[I 2023-08-19 13:00:04,120] Trial 1 finished with value: 0.02345188313804625 and parameters: {'num_topics': 63, 'alpha_categorical': 'symmetric', 'eta_categorical': 'scalar', 'eta': 0.21651648622399713}. Best is trial 0 with value: 0.028393254995785946.\n",
      "[I 2023-08-19 13:00:09,987] A new study created in memory with name: no-name-9f5697bf-60d5-4cb2-bca2-a90a1639c7bd\n",
      "[I 2023-08-19 13:00:20,963] Trial 0 finished with value: 0.07572688579335474 and parameters: {'num_topics': 26, 'alpha_categorical': 'scalar', 'eta_categorical': 'scalar', 'alpha': 0.2440361452758933, 'eta': 0.20312361975416615}. Best is trial 0 with value: 0.07572688579335474.\n",
      "[I 2023-08-19 13:00:33,636] Trial 1 finished with value: 0.026713096777507713 and parameters: {'num_topics': 73, 'alpha_categorical': 'scalar', 'eta_categorical': 'auto', 'alpha': 0.5104597875338254}. Best is trial 0 with value: 0.07572688579335474.\n",
      "[I 2023-08-19 13:00:38,693] A new study created in memory with name: no-name-e4edcac4-88e5-4059-9618-f3d1ba0916ee\n",
      "[I 2023-08-19 13:00:50,279] Trial 0 finished with value: 0.02352380189166434 and parameters: {'num_topics': 54, 'alpha_categorical': 'scalar', 'eta_categorical': 'auto', 'alpha': 0.6276860565591487}. Best is trial 0 with value: 0.02352380189166434.\n",
      "[I 2023-08-19 13:01:05,373] Trial 1 finished with value: 0.11742462654857973 and parameters: {'num_topics': 76, 'alpha_categorical': 'scalar', 'eta_categorical': 'symmetric', 'alpha': 0.33186892860588973}. Best is trial 1 with value: 0.11742462654857973.\n",
      "[I 2023-08-19 13:01:10,903] A new study created in memory with name: no-name-fb780169-2578-42f9-9ef5-2f44808f2e8c\n",
      "[I 2023-08-19 13:01:27,583] Trial 0 finished with value: 0.02879208691317263 and parameters: {'num_topics': 89, 'alpha_categorical': 'symmetric', 'eta_categorical': 'scalar', 'eta': 0.62018857104859}. Best is trial 0 with value: 0.02879208691317263.\n",
      "[I 2023-08-19 13:01:40,085] Trial 1 finished with value: 0.03803509326944082 and parameters: {'num_topics': 29, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 1 with value: 0.03803509326944082.\n",
      "[I 2023-08-19 13:01:47,577] A new study created in memory with name: no-name-10c50168-f1f4-4978-a1e2-4e884f89b8f3\n",
      "[I 2023-08-19 13:02:02,230] Trial 0 finished with value: 0.044789049300860986 and parameters: {'num_topics': 56, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'scalar', 'eta': 0.6597862104554766}. Best is trial 0 with value: 0.044789049300860986.\n",
      "[I 2023-08-19 13:02:16,912] Trial 1 finished with value: 0.03564596174510619 and parameters: {'num_topics': 52, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'scalar', 'eta': 0.8248097749844442}. Best is trial 0 with value: 0.044789049300860986.\n",
      "[I 2023-08-19 13:02:25,074] A new study created in memory with name: no-name-300a233b-7085-4d6b-8e97-318911a76983\n",
      "[I 2023-08-19 13:02:40,835] Trial 0 finished with value: 0.18414512505370584 and parameters: {'num_topics': 65, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.18414512505370584.\n",
      "[I 2023-08-19 13:02:57,192] Trial 1 finished with value: 0.19642790783626346 and parameters: {'num_topics': 67, 'alpha_categorical': 'symmetric', 'eta_categorical': 'symmetric'}. Best is trial 1 with value: 0.19642790783626346.\n",
      "[I 2023-08-19 13:03:04,297] A new study created in memory with name: no-name-495df53b-1fce-4816-9f61-34759d1d8910\n",
      "[I 2023-08-19 13:03:21,210] Trial 0 finished with value: 0.2512659754546283 and parameters: {'num_topics': 77, 'alpha_categorical': 'asymmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.2512659754546283.\n",
      "[I 2023-08-19 13:03:38,268] Trial 1 finished with value: 0.18873216373162513 and parameters: {'num_topics': 41, 'alpha_categorical': 'symmetric', 'eta_categorical': 'auto'}. Best is trial 0 with value: 0.2512659754546283.\n"
     ]
    }
   ],
   "source": [
    "save_models_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>lda_embedding</th>\n",
       "      <th>lda_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HT</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.800828</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>23.647413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.799833</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>22.379721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCLW</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.800833</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>25.818747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCLWN</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.812833</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>22.219262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.819834</td>\n",
       "      <td>0.091998</td>\n",
       "      <td>33.566865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACL</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.831834</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>33.911662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACLW</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.838855</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>28.696265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACLWN</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>423.086812</td>\n",
       "      <td>0.048004</td>\n",
       "      <td>32.202545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.824833</td>\n",
       "      <td>0.110003</td>\n",
       "      <td>36.662920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCL</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.838843</td>\n",
       "      <td>0.107988</td>\n",
       "      <td>37.488737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCLW</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.840824</td>\n",
       "      <td>0.062004</td>\n",
       "      <td>39.212126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCLWN</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>423.149832</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>40.608681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variant  segmentation  preprocess  lda_embedding  lda_training\n",
       "0       HT  5.998611e-03  422.800828       0.006001     23.647413\n",
       "1      HCL  5.998611e-03  422.799833       0.003976     22.379721\n",
       "2     HCLW  5.998611e-03  422.800833       0.004001     25.818747\n",
       "3    HCLWN  5.998611e-03  422.812833       0.003005     22.219262\n",
       "4       AT  1.692424e+09  422.819834       0.091998     33.566865\n",
       "5      ACL  1.692424e+09  422.831834       0.081002     33.911662\n",
       "6     ACLW  1.692424e+09  422.838855       0.039994     28.696265\n",
       "7    ACLWN  1.692424e+09  423.086812       0.048004     32.202545\n",
       "8       ST  4.204551e+01  422.824833       0.110003     36.662920\n",
       "9      SCL  4.204551e+01  422.838843       0.107988     37.488737\n",
       "10    SCLW  4.204551e+01  422.840824       0.062004     39.212126\n",
       "11   SCLWN  4.204551e+01  423.149832       0.067992     40.608681"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "embedding_model = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "def save_models_bertopic():\n",
    "    path_prefix = './results/models_bertopic/'\n",
    "    r_time = []\n",
    "    for v in HAS_e:\n",
    "        t_start = time()\n",
    "        bertopic = BERTopic(language='multilingual', embedding_model=embedding_model)\n",
    "        model = bertopic.fit(HAS_e[v]['text'])\n",
    "        t_end = time()\n",
    "        model.save(\n",
    "            f\"{path_prefix}{v}\",\n",
    "            serialization=\"safetensors\",\n",
    "            save_embedding_model=embedding_model,\n",
    "            save_ctfidf=True,\n",
    "        )\n",
    "        r_time.append(t_end - t_start)\n",
    "    HAS_t['bertopic_training'] = pd.Series(r_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_bertopic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>lda_embedding</th>\n",
       "      <th>lda_training</th>\n",
       "      <th>bertopic_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HT</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.800828</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>23.647413</td>\n",
       "      <td>21.273780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.799833</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>22.379721</td>\n",
       "      <td>9.136819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCLW</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.800833</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>25.818747</td>\n",
       "      <td>9.151057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCLWN</td>\n",
       "      <td>5.998611e-03</td>\n",
       "      <td>422.812833</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>22.219262</td>\n",
       "      <td>8.910228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.819834</td>\n",
       "      <td>0.091998</td>\n",
       "      <td>33.566865</td>\n",
       "      <td>20.321130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACL</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.831834</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>33.911662</td>\n",
       "      <td>20.947009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACLW</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>422.838855</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>28.696265</td>\n",
       "      <td>19.449470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACLWN</td>\n",
       "      <td>1.692424e+09</td>\n",
       "      <td>423.086812</td>\n",
       "      <td>0.048004</td>\n",
       "      <td>32.202545</td>\n",
       "      <td>18.919627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.824833</td>\n",
       "      <td>0.110003</td>\n",
       "      <td>36.662920</td>\n",
       "      <td>94.256775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCL</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.838843</td>\n",
       "      <td>0.107988</td>\n",
       "      <td>37.488737</td>\n",
       "      <td>90.736179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCLW</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>422.840824</td>\n",
       "      <td>0.062004</td>\n",
       "      <td>39.212126</td>\n",
       "      <td>63.794322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCLWN</td>\n",
       "      <td>4.204551e+01</td>\n",
       "      <td>423.149832</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>40.608681</td>\n",
       "      <td>63.153381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variant  segmentation  preprocess  lda_embedding  lda_training  \\\n",
       "0       HT  5.998611e-03  422.800828       0.006001     23.647413   \n",
       "1      HCL  5.998611e-03  422.799833       0.003976     22.379721   \n",
       "2     HCLW  5.998611e-03  422.800833       0.004001     25.818747   \n",
       "3    HCLWN  5.998611e-03  422.812833       0.003005     22.219262   \n",
       "4       AT  1.692424e+09  422.819834       0.091998     33.566865   \n",
       "5      ACL  1.692424e+09  422.831834       0.081002     33.911662   \n",
       "6     ACLW  1.692424e+09  422.838855       0.039994     28.696265   \n",
       "7    ACLWN  1.692424e+09  423.086812       0.048004     32.202545   \n",
       "8       ST  4.204551e+01  422.824833       0.110003     36.662920   \n",
       "9      SCL  4.204551e+01  422.838843       0.107988     37.488737   \n",
       "10    SCLW  4.204551e+01  422.840824       0.062004     39.212126   \n",
       "11   SCLWN  4.204551e+01  423.149832       0.067992     40.608681   \n",
       "\n",
       "    bertopic_training  \n",
       "0           21.273780  \n",
       "1            9.136819  \n",
       "2            9.151057  \n",
       "3            8.910228  \n",
       "4           20.321130  \n",
       "5           20.947009  \n",
       "6           19.449470  \n",
       "7           18.919627  \n",
       "8           94.256775  \n",
       "9           90.736179  \n",
       "10          63.794322  \n",
       "11          63.153381  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_t.to_parquet('./results/HAS_t.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
